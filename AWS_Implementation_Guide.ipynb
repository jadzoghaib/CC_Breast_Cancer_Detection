{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95d7471f",
   "metadata": {},
   "source": [
    "# AWS Migration: Step-by-Step Implementation Guide\n",
    "\n",
    "This notebook serves as a checklist and guide for migrating your Breast Cancer Prediction model to AWS. Follow these steps sequentially.\n",
    "\n",
    "## Prerequisites\n",
    "*   An active AWS Account.\n",
    "*   The `breastcancer_env.yaml` file on your local machine.\n",
    "*   The `clean-data.csv` file on your local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb303726",
   "metadata": {},
   "source": [
    "## Step 1: Create S3 Buckets (Storage)\n",
    "1.  Log in to the **AWS Console** and search for **S3**.\n",
    "2.  Click **Create bucket**.\n",
    "3.  **Bucket 1 (Data):** Name it something unique (e.g., `breast-cancer-data-jad-2025`).\n",
    "    *   Keep defaults (Block Public Access: On).\n",
    "    *   Click **Create bucket**.\n",
    "4.  **Bucket 2 (Models):** Name it something unique (e.g., `breast-cancer-models-jad-2025`).\n",
    "    *   Click **Create bucket**.\n",
    "5.  **Upload Data:**\n",
    "    *   Go into your **Data Bucket**.\n",
    "    *   Click **Upload** -> **Add files**.\n",
    "    *   Select your local `data/clean-data.csv`.\n",
    "    *   Click **Upload**.\n",
    "\n",
    "## Step 2: Create IAM Role (Permissions)\n",
    "This role allows your EC2 instance to write to your S3 buckets.\n",
    "1.  Search for **IAM** in the console.\n",
    "2.  Go to **Roles** -> **Create role**.\n",
    "3.  **Trusted entity type:** AWS Service.\n",
    "4.  **Service or use case:** EC2.\n",
    "5.  Click **Next**.\n",
    "6.  **Add permissions:** Search for and select `AmazonS3FullAccess`.\n",
    "    *   *Note: In a strict production environment, you would limit this to just your specific buckets, but FullAccess is fine for setup.*\n",
    "7.  Click **Next**.\n",
    "8.  **Role name:** `EC2-S3-Access-Role`.\n",
    "9.  Click **Create role**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33e7899",
   "metadata": {},
   "source": [
    "### Step 3: Launch EC2 Instance (For Training)\n",
    "We still need an EC2 instance, but now its primary role is **Model Training** and **Data Processing**, not hosting the website.\n",
    "\n",
    "1.  **Go to EC2 Dashboard** -> Launch Instance.\n",
    "2.  **Name:** `BreastCancerTraining`.\n",
    "3.  **OS:** Ubuntu 24.04 LTS.\n",
    "4.  **Instance Type:** `t3.medium` (Recommended for training) or `t2.micro` (Free tier, might be slow).\n",
    "5.  **Key Pair:** Create new -> `breast-cancer-key` -> Download `.pem`.\n",
    "6.  **Network Settings:**\n",
    "    *   Allow SSH traffic from My IP.\n",
    "    *   (Optional) Allow HTTP/HTTPS if you want to download things easily.\n",
    "7.  **Launch Instance**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610ebb7c",
   "metadata": {},
   "source": [
    "## Step 4: Create the Training Script\n",
    "Create a file named `train.py` on your local machine with the following content. \n",
    "**Important:** Replace `YOUR_SOURCE_DATA_BUCKET_NAME` and `YOUR_MODEL_BUCKET_NAME` with the actual names of the buckets you created in Step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ad451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# 1. UPDATE THESE WITH YOUR ACTUAL BUCKET NAMES\n",
    "SOURCE_BUCKET = 'breast-cancer-cleaneddata' \n",
    "MODEL_BUCKET = 'breast-cancer-prediction-models'\n",
    "DATA_FILE = 'clean-data.csv'\n",
    "LOCAL_DATA_PATH = 'data/clean-data.csv'\n",
    "\n",
    "# 1. Load Data\n",
    "if not os.path.exists(LOCAL_DATA_PATH):\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    print(f\"Downloading {DATA_FILE} from S3...\")\n",
    "    try:\n",
    "        s3 = boto3.client('s3')\n",
    "        s3.download_file(SOURCE_BUCKET, DATA_FILE, LOCAL_DATA_PATH)\n",
    "        print(\"Download successful.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading from S3: {e}\")\n",
    "        print(\"Make sure you updated SOURCE_BUCKET and that your EC2 role has S3 permissions.\")\n",
    "        raise\n",
    "\n",
    "data = pd.read_csv(LOCAL_DATA_PATH)\n",
    "\n",
    "# 2. Preprocessing (Cleaning)\n",
    "if 'Unnamed: 0' in data.columns: data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "if 'id' in data.columns: data.drop('id', axis=1, inplace=True)\n",
    "if 'Unnamed: 32' in data.columns: data.drop('Unnamed: 32', axis=1, inplace=True)\n",
    "\n",
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values\n",
    "\n",
    "# Encode Target\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 3. Define Pipeline (StandardScaler -> PCA -> SVM)\n",
    "pipeline = Pipeline([\n",
    "    ('scl', StandardScaler()),\n",
    "    ('pca', PCA(n_components=2)),\n",
    "    # Best params from Notebook (C=0.1, gamma=0.001, kernel='linear')\n",
    "    ('clf', SVC(C=0.1, gamma=0.001, kernel='linear', probability=True)) \n",
    "])\n",
    "\n",
    "# 4. Train\n",
    "print(\"Training model...\")\n",
    "pipeline.fit(X, y)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# 5. Save and Upload\n",
    "LOCAL_MODEL_PATH = 'model_v1.pkl'\n",
    "joblib.dump(pipeline, LOCAL_MODEL_PATH)\n",
    "print(f\"Model saved locally to {LOCAL_MODEL_PATH}\")\n",
    "\n",
    "print(\"Uploading to S3...\")\n",
    "s3 = boto3.client('s3')\n",
    "s3.upload_file(LOCAL_MODEL_PATH, MODEL_BUCKET, 'latest_model.pkl')\n",
    "print(f\"Success! Model uploaded to s3://{MODEL_BUCKET}/latest_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a079c3b",
   "metadata": {},
   "source": [
    "### Is this the most efficient model?\n",
    "\n",
    "**Short Answer:** Yes, this architecture (SVM with Scaling) was the top performer in your analysis. We have updated the script with your specific hyperparameters (`C=0.1`, `kernel='linear'`) based on your Grid Search results.\n",
    "\n",
    "**Detailed Explanation:**\n",
    "1.  **Why SVM?**\n",
    "    In your notebook `NB6 Comparison between different classifiers`, you compared Logistic Regression, LDA, KNN, CART, Naive Bayes, and SVM.\n",
    "    *   Initially, SVM performed poorly.\n",
    "    *   **However**, after you applied `StandardScaler` (Standardization), SVM became the **most accurate algorithm**, outperforming the others. This is why we selected `SVC` for your production script.\n",
    "\n",
    "2.  **Why PCA?**\n",
    "    Your notebooks (`NB5` and `NB6`) use Principal Component Analysis (PCA).\n",
    "    *   In `NB6`, you explicitly defined a pipeline: `StandardScaler` -> `PCA(n_components=2)` -> `SVC`.\n",
    "    *   Using `n_components=2` makes the model extremely **efficient** (fast to train, small to store) because it only looks at the 2 most important variance features instead of all 30.\n",
    "    *   *Trade-off:* If you want slightly higher accuracy at the cost of speed, you could increase `n_components` to 10 (as explored in `NB5`) or remove PCA entirely. But for a \"lightweight\" cloud deployment, keeping PCA is a smart move for efficiency.\n",
    "\n",
    "3.  **Why C=0.1?**\n",
    "    In `NB5`, you ran a `GridSearchCV` to find the best `C` (Regularization) and `gamma`.\n",
    "    *   We have updated the `train.py` script to use `C=0.1` and `kernel='linear'` as per your specific results.\n",
    "\n",
    "**Conclusion:**\n",
    "The `train.py` script represents the **best architecture** (Scaled SVM) found in your research. It is \"efficient\" because it balances high accuracy (via SVM) with low computational cost (via PCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e4a85b",
   "metadata": {},
   "source": [
    "## Step 5: Deploy to EC2\n",
    "Now that your infrastructure is ready and your code is written, let's run it.\n",
    "\n",
    "1.  **Connect to EC2:**\n",
    "    *   Open your terminal (WSL/Ubuntu).\n",
    "    *   Run the following command:\n",
    "    ```bash\n",
    "    ssh -i \"~/breast-cancer-key.pem\" ubuntu@18.184.78.242\n",
    "    ```\n",
    "\n",
    "2.  **Install Environment Manager (Micromamba):**\n",
    "    *(You have already completed this step)*\n",
    "    Run these commands inside the EC2 terminal:\n",
    "    ```bash\n",
    "    \"${SHELL}\" <(curl -L micro.mamba.pm/install.sh)\n",
    "    # Press Enter to accept defaults\n",
    "    source ~/.bashrc\n",
    "    ```\n",
    "\n",
    "3.  **Upload Files:**\n",
    "    **CRITICAL:** Do NOT run this in the EC2 terminal. Open a **NEW** terminal window (WSL/Ubuntu) on your local machine.\n",
    "    \n",
    "    Use `scp` to copy your files to the server.\n",
    "    ```bash\n",
    "    # 1. Upload Environment File\n",
    "    scp -i \"~/breast-cancer-key.pem\" \"/mnt/c/Users/Jad Zoghaib/OneDrive/Desktop/CC_Breast_Cancer/Breast-cancer-risk-prediction/breastcancer_env.yaml\" ubuntu@18.184.78.242:~/\n",
    "    \n",
    "    # 2. Upload Training Script\n",
    "    scp -i \"~/breast-cancer-key.pem\" \"/mnt/c/Users/Jad Zoghaib/OneDrive/Desktop/CC_Breast_Cancer/Breast-cancer-risk-prediction/train.py\" ubuntu@18.184.78.242:~/\n",
    "    ```\n",
    "\n",
    "4.  **Setup & Run (Back in EC2 Terminal):**\n",
    "    ```bash\n",
    "    # Create environment\n",
    "    micromamba create -f breastcancer_env.yaml\n",
    "    \n",
    "    # Activate\n",
    "    micromamba activate breastcancer\n",
    "    \n",
    "    # Install boto3 (if missing)\n",
    "    micromamba install boto3\n",
    "    \n",
    "    # Run the training\n",
    "    python train.py\n",
    "    ```\n",
    "\n",
    "5.  **Verify:**\n",
    "    Check your S3 bucket \"Models\". You should see `latest_model.pkl`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e2b1c4",
   "metadata": {},
   "source": [
    "# Phase 1: The Serverless Application (Inference)\n",
    "We will use **AWS Lambda** for the backend logic (running the model) and **Amazon S3** to host the static website.\n",
    "\n",
    "### Step 6: Create the Lambda Function\n",
    "This function will fetch the model from S3, load it, and make a prediction.\n",
    "\n",
    "1.  **Create IAM Role (Permissions):**\n",
    "    *   Go to **IAM** -> **Roles** -> **Create role**.\n",
    "    *   Trusted entity: **AWS Service** -> **Lambda**.\n",
    "    *   **Add permissions:** Search for and select:\n",
    "        *   `AmazonS3FullAccess` (Read Model)\n",
    "        *   `AmazonDynamoDBFullAccess` (Save Records)\n",
    "        *   `AmazonSNSFullAccess` (Send Emails)\n",
    "    *   **Role name:** `LambdaMLRole`.\n",
    "    *   Click **Create role**.\n",
    "\n",
    "2.  **Create Function:**\n",
    "    *   Go to **AWS Lambda** -> **Create Function**.\n",
    "    *   **Name:** `PredictorLambda`.\n",
    "    *   **Runtime:** **Python 3.10**.\n",
    "    *   **Architecture:** **x86_64**.\n",
    "    *   **Permissions:** Use an existing role -> Select `LambdaMLRole`.\n",
    "    *   **Create Function**.\n",
    "\n",
    "3.  **Add Layers (Crucial):**\n",
    "    *   **Layer 1 (Scikit-Learn):** Create a custom layer named `sklearn-light` using the `sklearn_light.zip` generated in `Lambda_Layer_Fix.ipynb`. Add it to the function.\n",
    "    *   **Layer 2 (Numpy):** Add a layer via **Specify an ARN**: `arn:aws:lambda:eu-central-1:770693421928:layer:Klayers-p310-numpy:16`.\n",
    "\n",
    "4.  **Code Source:**\n",
    "    *   Paste the code below into `lambda_function.py`.\n",
    "    *   **Deploy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af36860",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'boto3'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mboto3\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'boto3'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "import joblib\n",
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "BUCKET_NAME = 'breast-cancer-prediction-models'\n",
    "MODEL_KEY = 'latest_model.pkl'\n",
    "DYNAMODB_TABLE = 'Patient_Entries'  # Updated to match your existing table\n",
    "SNS_TOPIC_ARN = 'arn:aws:sns:eu-central-1:469541406278:MalignantAlerts'\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "dynamodb = boto3.resource('dynamodb')\n",
    "sns = boto3.client('sns')\n",
    "table = dynamodb.Table(DYNAMODB_TABLE)\n",
    "\n",
    "def load_model_from_s3():\n",
    "    print(\"Loading model from S3...\")\n",
    "    response = s3.get_object(Bucket=BUCKET_NAME, Key=MODEL_KEY)\n",
    "    model_stream = BytesIO(response['Body'].read())\n",
    "    model = joblib.load(model_stream)\n",
    "    print(\"Model loaded successfully.\")\n",
    "    return model\n",
    "\n",
    "# Load model globally to reuse across invocations\n",
    "model = load_model_from_s3()\n",
    "\n",
    "def process_doctor_feedback(body):\n",
    "    \"\"\"Handles the Tick/Cross feedback from the doctor.\"\"\"\n",
    "    case_id = body.get('id')\n",
    "    resolution = body.get('resolution')  # 'confirmed_malignant' or 'confirmed_benign'\n",
    "\n",
    "    if not case_id or not resolution:\n",
    "        return {'statusCode': 400, 'body': json.dumps('Missing id or resolution')}\n",
    "\n",
    "    print(f\"Processing feedback for Case {case_id}: {resolution}\")\n",
    "\n",
    "    # Update DynamoDB\n",
    "    try:\n",
    "        table.update_item(\n",
    "            Key={'id': case_id},\n",
    "            UpdateExpression=\"SET doctor_resolution = :r, status = :s\",\n",
    "            ExpressionAttributeValues={\n",
    "                ':r': resolution,\n",
    "                ':s': 'Resolved'\n",
    "            }\n",
    "        )\n",
    "        return {'statusCode': 200, 'body': json.dumps(f\"Case {case_id} resolved as {resolution}\")}\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating DynamoDB: {str(e)}\")\n",
    "        return {'statusCode': 500, 'body': json.dumps(f\"Database error: {str(e)}\")}\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    try:\n",
    "        print(\"Received event:\", json.dumps(event))\n",
    "        \n",
    "        # Parse body\n",
    "        if 'body' in event:\n",
    "            if isinstance(event['body'], str):\n",
    "                body = json.loads(event['body'])\n",
    "            else:\n",
    "                body = event['body']\n",
    "        else:\n",
    "            body = event\n",
    "\n",
    "        # CHECK OPERATION TYPE\n",
    "        if body.get('operation') == 'feedback':\n",
    "            return process_doctor_feedback(body)\n",
    "\n",
    "        # --- PREDICTION LOGIC ---\n",
    "        # Expecting 'features' list in the body\n",
    "        features = body.get('features')\n",
    "        case_id = body.get('id', 'unknown_id')\n",
    "\n",
    "        if not features:\n",
    "            return {\n",
    "                'statusCode': 400,\n",
    "                'body': json.dumps(\"Error: 'features' list is required.\")\n",
    "            }\n",
    "\n",
    "        # Predict directly from list (No Pandas needed)\n",
    "        # Scikit-learn expects a 2D array: [[f1, f2, ...]]\n",
    "        prediction = model.predict([features])\n",
    "        result = 'M' if prediction[0] == 1 else 'B'\n",
    "\n",
    "        print(f\"Prediction for {case_id}: {result}\")\n",
    "\n",
    "        # Save to DynamoDB\n",
    "        item = {\n",
    "            'id': case_id,\n",
    "            'features': str(features),  # Store as string or list\n",
    "            'prediction': result,\n",
    "            'status': 'Pending Review'\n",
    "        }\n",
    "        table.put_item(Item=item)\n",
    "\n",
    "        # Send SNS Alert if Malignant\n",
    "        if result == 'M':\n",
    "            message = (\n",
    "                f\"URGENT: Malignant Case Detected\\n\\n\"\n",
    "                f\"Case ID: {case_id}\\n\"\n",
    "                f\"Prediction: Malignant (M)\\n\"\n",
    "                f\"Status: Pending Doctor Review\\n\\n\"\n",
    "                f\"Please log in to the dashboard to review this case immediately.\"\n",
    "            )\n",
    "            sns.publish(\n",
    "                TopicArn=SNS_TOPIC_ARN,\n",
    "                Message=message,\n",
    "                Subject=f\"Alert: Malignant Case {case_id}\"\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            'statusCode': 200,\n",
    "            'body': json.dumps({'prediction': result, 'id': case_id})\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps(f\"Internal Server Error: {str(e)}\")\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ff1345",
   "metadata": {},
   "source": [
    "### Step 7: Create API Gateway\n",
    "This allows your HTML page to talk to the Lambda function.\n",
    "\n",
    "1.  Go to **API Gateway** -> **HTTP API** -> Build.\n",
    "2.  **API Name:** `BreastCancerAPI`.\n",
    "3.  **Integrations:** Add Integration -> Lambda -> Choose `PredictorLambda`.\n",
    "4.  **Configure Routes:**\n",
    "    *   Method: `POST`\n",
    "    *   Resource Path: `/predict`\n",
    "    *   Integration Target: `PredictorLambda`\n",
    "5.  **Create**.\n",
    "6.  **CORS Configuration:** (Crucial for web access)\n",
    "    *   Go to **CORS** in the sidebar.\n",
    "    *   Access-Control-Allow-Origin: `*`\n",
    "    *   Access-Control-Allow-Methods: `POST`\n",
    "    *   Access-Control-Allow-Headers: `content-type`\n",
    "    *   Save.\n",
    "7.  **Copy the Invoke URL** (e.g., `https://xyz.execute-api.us-east-1.amazonaws.com`).\n",
    "\n",
    "### Step 8: Host Frontend on S3\n",
    "1.  Create a file named `BreastCancerPredictorFrontEnd.html` locally.\n",
    "2.  **Update the JavaScript fetch URL** to point to your new API Gateway URL + `/predict`.\n",
    "3.  Go to your S3 Bucket (`breast-cancer-app-frontend`).\n",
    "4.  **Upload** `BreastCancerPredictorFrontEnd.html`.\n",
    "5.  Go to **Properties** -> **Static website hosting** -> Enable.\n",
    "6.  **Index document:** `BreastCancerPredictorFrontEnd.html`.\n",
    "7.  Save.\n",
    "8.  **Open the Bucket Website Endpoint** to test your app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c787bb9",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (760329767.py, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mbody { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; max-width: 1000px; margin: 0 auto; padding: 20px; background-color: #f8f9fa; color: #333; }\u001b[39m\n                                                                                       ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Breast Cancer Risk System</title>\n",
    "    <style>\n",
    "        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; max-width: 1000px; margin: 0 auto; padding: 20px; background-color: #f8f9fa; color: #333; }\n",
    "        .view { display: none; animation: fadeIn 0.5s; }\n",
    "        .active { display: block; }\n",
    "        @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }\n",
    "        \n",
    "        /* Buttons */\n",
    "        .btn { padding: 12px 24px; margin: 5px; cursor: pointer; border-radius: 6px; font-size: 15px; border: none; transition: all 0.2s; font-weight: 600; }\n",
    "        .btn:disabled { opacity: 0.6; cursor: not-allowed; }\n",
    "        .btn-primary { background-color: #007bff; color: white; }\n",
    "        .btn-primary:hover { background-color: #0056b3; transform: translateY(-1px); }\n",
    "        .btn-success { background-color: #28a745; color: white; }\n",
    "        .btn-success:hover { background-color: #218838; }\n",
    "        .btn-danger { background-color: #dc3545; color: white; }\n",
    "        .btn-danger:hover { background-color: #c82333; }\n",
    "        .btn-outline { background: transparent; border: 1px solid #007bff; color: #007bff; }\n",
    "        .btn-outline:hover { background: #e7f1ff; }\n",
    "\n",
    "        /* File Upload */\n",
    "        .upload-area { border: 2px dashed #ccc; padding: 30px; text-align: center; background: white; border-radius: 10px; margin: 20px 0; transition: 0.3s; }\n",
    "        .upload-area:hover { border-color: #007bff; background: #f0f8ff; }\n",
    "        \n",
    "        /* Table */\n",
    "        .table-container { max-height: 400px; overflow: auto; margin: 20px 0; border: 1px solid #dee2e6; border-radius: 5px; background: white; display: none; }\n",
    "        table { width: 100%; border-collapse: collapse; font-size: 13px; white-space: nowrap; }\n",
    "        th, td { padding: 10px; text-align: left; border-bottom: 1px solid #dee2e6; }\n",
    "        th { background-color: #e9ecef; position: sticky; top: 0; z-index: 10; font-weight: 600; }\n",
    "        tr:hover { background-color: #f8f9fa; }\n",
    "\n",
    "        /* Cards */\n",
    "        .case-card { background: white; border-left: 5px solid #dc3545; border-radius: 5px; padding: 15px; margin: 10px 0; display: flex; justify-content: space-between; align-items: center; box-shadow: 0 2px 8px rgba(0,0,0,0.05); }\n",
    "        .status-badge { padding: 4px 8px; border-radius: 4px; font-size: 12px; font-weight: bold; }\n",
    "        .status-malignant { background: #ffebee; color: #c62828; }\n",
    "        \n",
    "        /* Logs */\n",
    "        #analysis-log { background: #2d2d2d; color: #00ff00; padding: 15px; border-radius: 5px; font-family: monospace; max-height: 200px; overflow-y: auto; margin-top: 20px; display: none; }\n",
    "    </style>\n",
    "    <script>\n",
    "        // --- CONFIGURATION ---\n",
    "        const PREDICT_URL = 'https://qu6y4f29lg.execute-api.eu-central-1.amazonaws.com/predict';\n",
    "\n",
    "        // --- CONSTANTS ---\n",
    "        const FEATURE_NAMES = [\n",
    "            \"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\", \"compactness_mean\", \"concavity_mean\", \"concave points_mean\", \"symmetry_mean\", \"fractal_dimension_mean\",\n",
    "            \"radius_se\", \"texture_se\", \"perimeter_se\", \"area_se\", \"smoothness_se\", \"compactness_se\", \"concavity_se\", \"concave points_se\", \"symmetry_se\", \"fractal_dimension_se\",\n",
    "            \"radius_worst\", \"texture_worst\", \"perimeter_worst\", \"area_worst\", \"smoothness_worst\", \"compactness_worst\", \"concavity_worst\", \"concave points_worst\", \"symmetry_worst\", \"fractal_dimension_worst\"\n",
    "        ];\n",
    "\n",
    "        // --- STATE ---\n",
    "        let loadedData = []; // Stores objects: { id: string, features: number[] }\n",
    "        let openCases = [];  // Stores Malignant cases waiting for review\n",
    "\n",
    "        // --- NAVIGATION ---\n",
    "        function showView(viewId) {\n",
    "            document.querySelectorAll('.view').forEach(el => el.classList.remove('active'));\n",
    "            document.getElementById(viewId).classList.add('active');\n",
    "            if(viewId === 'cases-view') renderOpenCases();\n",
    "        }\n",
    "\n",
    "        // --- FILE HANDLING ---\n",
    "        function handleFileUpload(event) {\n",
    "            const file = event.target.files[0];\n",
    "            if (!file) return;\n",
    "\n",
    "            const reader = new FileReader();\n",
    "            reader.onload = function(e) {\n",
    "                const text = e.target.result;\n",
    "                parseCSV(text, file.name);\n",
    "            };\n",
    "            reader.readAsText(file);\n",
    "        }\n",
    "\n",
    "        function parseCSV(csvText, fileName) {\n",
    "            try {\n",
    "                // 1. Extract Base ID from Filename\n",
    "                // Example: \"sample_patient_569.csv\" -> \"569\"\n",
    "                const nameNoExt = fileName.substring(0, fileName.lastIndexOf('.')) || fileName;\n",
    "                const parts = nameNoExt.split(/[_-\\s]+/);\n",
    "                const baseId = parts[parts.length - 1];\n",
    "\n",
    "                const lines = csvText.split('\\n').filter(line => line.trim() !== '');\n",
    "                loadedData = [];\n",
    "                \n",
    "                // Determine start row (Skip header if present)\n",
    "                let startRow = 0;\n",
    "                if (/[a-zA-Z]/.test(lines[0])) {\n",
    "                    startRow = 1;\n",
    "                }\n",
    "\n",
    "                // Parse rows\n",
    "                const tempRows = [];\n",
    "                for (let i = startRow; i < Math.min(lines.length, 101); i++) { \n",
    "                    const rawValues = lines[i].split(',');\n",
    "                    \n",
    "                    // Filter for numeric values (to find features)\n",
    "                    const numericValues = rawValues\n",
    "                        .map(v => parseFloat(v))\n",
    "                        .filter(v => !isNaN(v));\n",
    "\n",
    "                    // We need at least 30 numeric features\n",
    "                    if (numericValues.length >= 30) {\n",
    "                        const features = numericValues.slice(-30);\n",
    "                        tempRows.push(features);\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                if (tempRows.length === 0) {\n",
    "                    alert(\"Could not parse any valid rows with 30 numeric features. Please check your CSV format.\");\n",
    "                    return;\n",
    "                }\n",
    "\n",
    "                // Assign IDs based on filename\n",
    "                loadedData = tempRows.map((features, index) => {\n",
    "                    // If single row, use the filename ID directly (e.g. \"569\")\n",
    "                    // If multiple rows, append index (e.g. \"569-1\", \"569-2\")\n",
    "                    let caseId = baseId;\n",
    "                    if (tempRows.length > 1) {\n",
    "                        caseId = `${baseId}-${index + 1}`;\n",
    "                    }\n",
    "                    return { id: caseId, features: features };\n",
    "                });\n",
    "\n",
    "                renderTable(loadedData);\n",
    "                document.getElementById('confirm-btn').disabled = false;\n",
    "                \n",
    "            } catch (e) {\n",
    "                console.error(e);\n",
    "                alert(\"Error parsing CSV: \" + e.message);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        function renderTable(data) {\n",
    "            const container = document.getElementById('table-container');\n",
    "            const tableHead = document.getElementById('data-table-head');\n",
    "            const tableBody = document.getElementById('data-table-body');\n",
    "            \n",
    "            // Clear previous\n",
    "            tableHead.innerHTML = '';\n",
    "            tableBody.innerHTML = '';\n",
    "\n",
    "            // Headers\n",
    "            const headerRow = document.createElement('tr');\n",
    "            \n",
    "            // ID Column Header\n",
    "            const thId = document.createElement('th');\n",
    "            thId.innerText = \"Case ID\"; \n",
    "            thId.style.minWidth = \"80px\";\n",
    "            headerRow.appendChild(thId);\n",
    "            \n",
    "            // Feature Headers\n",
    "            FEATURE_NAMES.forEach(h => {\n",
    "                const th = document.createElement('th');\n",
    "                th.innerText = h;\n",
    "                headerRow.appendChild(th);\n",
    "            });\n",
    "            tableHead.appendChild(headerRow);\n",
    "\n",
    "            // Rows\n",
    "            data.forEach((item) => {\n",
    "                const tr = document.createElement('tr');\n",
    "                \n",
    "                // ID Cell\n",
    "                const tdId = document.createElement('td');\n",
    "                tdId.innerText = item.id; \n",
    "                tdId.style.fontWeight = \"bold\";\n",
    "                tdId.style.backgroundColor = \"#f8f9fa\";\n",
    "                tr.appendChild(tdId);\n",
    "\n",
    "                // Feature Cells\n",
    "                item.features.forEach(val => {\n",
    "                    const td = document.createElement('td');\n",
    "                    td.innerText = val; \n",
    "                    tr.appendChild(td);\n",
    "                });\n",
    "                tableBody.appendChild(tr);\n",
    "            });\n",
    "\n",
    "            container.style.display = 'block';\n",
    "        }\n",
    "\n",
    "        function confirmData() {\n",
    "            if (loadedData.length > 0) {\n",
    "                document.getElementById('analyze-btn').disabled = false;\n",
    "                alert(`Data Confirmed! ${loadedData.length} patient records ready for analysis.`);\n",
    "            } else {\n",
    "                alert(\"No data to confirm. Please upload a valid CSV.\");\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // --- LOGIC: BATCH ANALYSIS ---\n",
    "        async function analyzeRisk() {\n",
    "            if (!loadedData || loadedData.length === 0) {\n",
    "                alert(\"No data loaded. Please upload a CSV first.\");\n",
    "                return;\n",
    "            }\n",
    "\n",
    "            showView('analyze-view');\n",
    "            \n",
    "            // MIRROR TABLE TO ANALYZE VIEW\n",
    "            const originalTable = document.getElementById('table-container').innerHTML;\n",
    "            const targetContainer = document.getElementById('analysis-table-container');\n",
    "            targetContainer.innerHTML = originalTable;\n",
    "            targetContainer.style.display = 'block';\n",
    "\n",
    "            const logDiv = document.getElementById('analysis-log');\n",
    "            logDiv.style.display = 'block';\n",
    "            logDiv.innerHTML = \"Starting analysis...\\n\";\n",
    "\n",
    "            let processed = 0;\n",
    "            \n",
    "            // Iterate through loaded data\n",
    "            for (let i = 0; i < loadedData.length; i++) {\n",
    "                const item = loadedData[i];\n",
    "                const features = item.features;\n",
    "                const patientId = item.id; \n",
    "\n",
    "                try {\n",
    "                    // Call API\n",
    "                    const response = await fetch(PREDICT_URL, {\n",
    "                        method: 'POST',\n",
    "                        headers: { 'Content-Type': 'application/json' },\n",
    "                        body: JSON.stringify({ features: features, id: patientId })\n",
    "                    });\n",
    "\n",
    "                    // ERROR HANDLING: Check if the request failed (e.g. 500 or 400)\n",
    "                    if (!response.ok) {\n",
    "                        const errorText = await response.text();\n",
    "                        throw new Error(`Server Error (${response.status}): ${errorText}`);\n",
    "                    }\n",
    "\n",
    "                    const result = await response.json();\n",
    "                    const prediction = result.prediction;\n",
    "\n",
    "                    // VALIDATION: Check if prediction is missing\n",
    "                    if (prediction === undefined) {\n",
    "                        throw new Error(\"Invalid response: 'prediction' field missing.\");\n",
    "                    }\n",
    "\n",
    "                    processed++;\n",
    "                    \n",
    "                    if (prediction === 'M') {\n",
    "                        // LOGIC: If Malignant -> Add to Open Cases\n",
    "                        openCases.push({\n",
    "                            id: patientId,\n",
    "                            features: features,\n",
    "                            date: new Date().toLocaleDateString(),\n",
    "                            status: 'Malignant'\n",
    "                        });\n",
    "                        logDiv.innerHTML += `[${patientId}] -> MALIGNANT (Added to Open Cases)\\n`;\n",
    "                    } else {\n",
    "                        // LOGIC: If Benign -> Auto-save to DB\n",
    "                        logDiv.innerHTML += `[${patientId}] -> Benign (Archived to DB)\\n`;\n",
    "                    }\n",
    "\n",
    "                } catch (error) {\n",
    "                    logDiv.innerHTML += `[${patientId}] Error: ${error.message}\\n`;\n",
    "                }\n",
    "                \n",
    "                // Auto-scroll log\n",
    "                logDiv.scrollTop = logDiv.scrollHeight;\n",
    "            }\n",
    "\n",
    "            logDiv.innerHTML += `\\nAnalysis Complete. ${openCases.length} new cases require review.`;\n",
    "        }\n",
    "\n",
    "        // --- LOGIC: OPEN CASES ---\n",
    "        function renderOpenCases() {\n",
    "            const list = document.getElementById('cases-list');\n",
    "            list.innerHTML = '';\n",
    "\n",
    "            if (openCases.length === 0) {\n",
    "                list.innerHTML = \"<p style='text-align:center; color:#666;'>No open cases found.</p>\";\n",
    "                return;\n",
    "            }\n",
    "\n",
    "            openCases.forEach(c => {\n",
    "                const item = document.createElement('div');\n",
    "                item.className = 'case-card';\n",
    "                item.innerHTML = `\n",
    "                    <div>\n",
    "                        <strong>ID: ${c.id}</strong> <span style=\"color:#999; font-size:0.9em\">(${c.date})</span><br>\n",
    "                        <span class=\"status-badge status-malignant\">Potential Malignancy</span>\n",
    "                    </div>\n",
    "                    <div>\n",
    "                        <button class=\"btn btn-success\" onclick=\"resolveCase('${c.id}', 'Confirmed')\">‚úì Confirm</button>\n",
    "                        <button class=\"btn btn-danger\" onclick=\"resolveCase('${c.id}', 'False Positive')\">X False Positive</button>\n",
    "                    </div>\n",
    "                `;\n",
    "                list.appendChild(item);\n",
    "            });\n",
    "        }\n",
    "\n",
    "        function resolveCase(id, resolution) {\n",
    "            // Find the case data to send back to the backend\n",
    "            const caseData = openCases.find(c => c.id === id);\n",
    "            const features = caseData ? caseData.features : [];\n",
    "            \n",
    "            if(confirm(`Mark case ${id} as ${resolution}?`)) {\n",
    "                \n",
    "                // 1. Prepare the payload\n",
    "                // We add 'operation': 'feedback' so the Lambda knows this isn't a new prediction\n",
    "                const payload = {\n",
    "                    operation: 'feedback',\n",
    "                    id: id,\n",
    "                    resolution: resolution\n",
    "                };\n",
    "\n",
    "                // 2. Send to API\n",
    "                fetch(PREDICT_URL, {\n",
    "                    method: 'POST',\n",
    "                    headers: { 'Content-Type': 'application/json' },\n",
    "                    body: JSON.stringify(payload)\n",
    "                })\n",
    "                .then(response => {\n",
    "                    if (!response.ok) {\n",
    "                        throw new Error(`Server responded with ${response.status}`);\n",
    "                    }\n",
    "                    return response.json();\n",
    "                })\n",
    "                .then(data => {\n",
    "                    // 3. Success Handling\n",
    "                    alert(`‚úÖ Success! Feedback saved to DynamoDB.\\nCase ${id} marked as ${resolution}.`);\n",
    "                    \n",
    "                    // Remove from the list\n",
    "                    openCases = openCases.filter(c => c.id !== id);\n",
    "                    renderOpenCases();\n",
    "                })\n",
    "                .catch(error => {\n",
    "                    // 4. Error Handling (The \"Why it didn't work\" part)\n",
    "                    console.error(\"Feedback Error:\", error);\n",
    "                    alert(`‚ùå Action Failed: Could not save to DynamoDB.\\n\\nReason: ${error.message}\\n\\nWhy is this happening?\\n1. The Lambda function might not be updated yet to handle \"feedback\" requests.\\n2. The DynamoDB table might be missing or named incorrectly.\\n3. The API Gateway might be blocking the request (CORS).\\n\\nPlease check your Lambda logs for more details.`);\n",
    "                });\n",
    "            }\n",
    "        }\n",
    "    </script>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "    <!-- HOME VIEW -->\n",
    "    <div id=\"home-view\" class=\"view active\">\n",
    "        <h1 style=\"text-align:center;\">Breast Cancer Risk System</h1>\n",
    "        \n",
    "        <!-- Upload Section -->\n",
    "        <div class=\"upload-area\">\n",
    "            <h3>üìÇ Upload Patient Data</h3>\n",
    "            <p>Drag and drop your CSV file here or click to browse</p>\n",
    "            <input type=\"file\" id=\"csvFileInput\" accept=\".csv\" onchange=\"handleFileUpload(event)\" />\n",
    "        </div>\n",
    "\n",
    "        <!-- Data Preview Table -->\n",
    "        <div id=\"table-container\" class=\"table-container\">\n",
    "            <table id=\"data-table\">\n",
    "                <thead id=\"data-table-head\"></thead>\n",
    "                <tbody id=\"data-table-body\"></tbody>\n",
    "            </table>\n",
    "        </div>\n",
    "\n",
    "        <!-- Actions -->\n",
    "        <div style=\"text-align:center; margin-top: 20px;\">\n",
    "            <button id=\"confirm-btn\" class=\"btn btn-success\" onclick=\"confirmData()\" disabled>‚úì Confirm Data</button>\n",
    "            <button id=\"analyze-btn\" class=\"btn btn-primary\" onclick=\"analyzeRisk()\" disabled>‚ö° Analyze Risk</button>\n",
    "            <button class=\"btn btn-outline\" onclick=\"showView('cases-view')\">üìÇ Open Cases</button>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <!-- ANALYZE VIEW (Log Output) -->\n",
    "    <div id=\"analyze-view\" class=\"view\">\n",
    "        <button onclick=\"showView('home-view')\" class=\"btn btn-outline\">‚Üê Back to Home</button>\n",
    "        <h2>Analysis in Progress</h2>\n",
    "        \n",
    "        <!-- MIRRORED TABLE -->\n",
    "        <div id=\"analysis-table-container\" class=\"table-container\"></div>\n",
    "\n",
    "        <p>Processing uploaded records against the AI model...</p>\n",
    "        \n",
    "        <div id=\"analysis-log\"></div>\n",
    "        \n",
    "        <div style=\"margin-top: 20px; text-align: center;\">\n",
    "            <button class=\"btn btn-primary\" onclick=\"showView('cases-view')\">Go to Open Cases Review</button>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <!-- OPEN CASES VIEW -->\n",
    "    <div id=\"cases-view\" class=\"view\">\n",
    "        <button onclick=\"showView('home-view')\" class=\"btn btn-outline\">‚Üê Back to Home</button>\n",
    "        <h2>Open Cases</h2>\n",
    "        <p>The following cases were flagged as <strong>Malignant</strong> and require doctor confirmation.</p>\n",
    "        <div id=\"cases-list\"></div>\n",
    "    </div>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd26f9c",
   "metadata": {},
   "source": [
    "# Phase 2: Continuous Learning (Retraining)\n",
    "We will use the EC2 instance to retrain the model periodically.\n",
    "\n",
    "### Step 9: Automate Retraining (Cron Job)\n",
    "Since you already set up the environment and uploaded `train.py` in **Step 5**, you don't need to do it again. We just need to schedule the script to run automatically.\n",
    "\n",
    "1.  **SSH into your EC2 instance** (if not connected).\n",
    "2.  **Edit the Cron Table:**\n",
    "    ```bash\n",
    "    crontab -e\n",
    "    ```\n",
    "    *(Select `1` for `nano` if asked for an editor)*\n",
    "\n",
    "3.  **Add the Schedule:**\n",
    "    Scroll to the bottom of the file and add this line. This runs the training every Sunday at midnight and saves the output to a log file.\n",
    "    ```bash\n",
    "    0 0 * * 0 /home/ubuntu/micromamba/envs/breastcancer/bin/python /home/ubuntu/train.py >> /home/ubuntu/train.log 2>&1\n",
    "    ```\n",
    "\n",
    "4.  **Save and Exit:**\n",
    "    *   Press `Ctrl+O`, `Enter` to save.\n",
    "    *   Press `Ctrl+X` to exit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_first_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
