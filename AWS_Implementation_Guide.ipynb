{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95d7471f",
   "metadata": {},
   "source": [
    "# üè• Breast Cancer Risk Prediction: Complete AWS Implementation Guide\n",
    "\n",
    "This notebook documents the end-to-end process of building, deploying, and automating the Breast Cancer Risk Prediction system on AWS.\n",
    "\n",
    "## üèóÔ∏è Architecture Overview\n",
    "1.  **Training**: EC2 instance trains a Logistic Regression model using data from S3.\n",
    "2.  **Prediction**: Users submit data via a Web UI (EC2) -> API Gateway -> Lambda -> Model.\n",
    "3.  **Storage**: All predictions are stored in DynamoDB.\n",
    "4.  **Alerts**: High-risk (Malignant) predictions trigger an SNS Email Alert.\n",
    "5.  **Continuous Learning**: A weekly EventBridge schedule triggers a Sync Lambda to move confirmed cases from DynamoDB back to S3 for retraining.\n",
    "\n",
    "---\n",
    "## üõ†Ô∏è Prerequisites\n",
    "*   AWS Account with Admin Access.\n",
    "*   `clean-data.csv` (Initial Dataset).\n",
    "*   `breastcancer_env.yaml` (Conda Environment).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb303726",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Phase 1: Storage & Permissions\n",
    "\n",
    "### A. S3 Buckets\n",
    "We created two S3 buckets to separate data from artifacts.\n",
    "1.  **`breast-cancer-cleaneddata`**: Stores the \"Golden Copy\" of the dataset (`clean-data.csv` and versioned files like `patient_data_v1.csv`).\n",
    "2.  **`breast-cancer-models`**: Stores the trained model artifacts (`model.pkl`, `scaler.pkl`).\n",
    "\n",
    "### B. IAM Role (`EC2-S3-Access-Role`)\n",
    "This role allows our EC2 instance to read/write to S3 without hardcoding credentials.\n",
    "*   **Trusted Entity**: EC2\n",
    "*   **Permissions**: `AmazonS3FullAccess`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33e7899",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Phase 2: Model Training (EC2)\n",
    "\n",
    "We launched an **Ubuntu t3.medium** EC2 instance to handle the training workload.\n",
    "\n",
    "### A. Setup\n",
    "1.  **Instance Name**: `BreastCancerTraining`\n",
    "2.  **Key Pair**: `breast-cancer-key.pem`\n",
    "3.  **Environment**: Installed Miniconda and created `breastcancer_env`.\n",
    "\n",
    "### B. The Training Script (`train.py`)\n",
    "This script is the heart of the ML pipeline. It:\n",
    "1.  Downloads the latest data from S3.\n",
    "2.  Trains a Logistic Regression model.\n",
    "3.  Evaluates accuracy.\n",
    "4.  Uploads the trained model back to S3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ad451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DATA_PATH = 'data/clean-data.csv'  # Path to your dataset\n",
    "MODEL_FILENAME = 'latest_model.pkl'\n",
    "BUCKET_NAME = 'breast-cancer-prediction-models'\n",
    "\n",
    "def train_and_upload_model():\n",
    "    # 1. Load Data\n",
    "    if not os.path.exists(DATA_PATH):\n",
    "        print(f\"Error: Data file not found at {DATA_PATH}\")\n",
    "        # Fallback for demonstration if file is missing\n",
    "        from sklearn.datasets import load_breast_cancer\n",
    "        data = load_breast_cancer()\n",
    "        X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "        y = data.target\n",
    "        # Note: In Wisconsin dataset, 0 is Malignant, 1 is Benign usually, \n",
    "        # but check your specific CSV labels. \n",
    "        # Assuming 1=Malignant for this generic fallback.\n",
    "    else:\n",
    "        df = pd.read_csv(DATA_PATH)\n",
    "        # Basic preprocessing (adjust based on your actual data columns)\n",
    "        # Assuming 'diagnosis' is the target and 'id' is not a feature\n",
    "        if 'diagnosis' in df.columns:\n",
    "            y = df['diagnosis'].map({'M': 1, 'B': 0}) # Encode M as 1, B as 0\n",
    "            X = df.drop(['diagnosis', 'id', 'Unnamed: 32'], axis=1, errors='ignore')\n",
    "        else:\n",
    "            # Fallback if column names differ\n",
    "            print(\"Warning: 'diagnosis' column not found. Using last column as target.\")\n",
    "            X = df.iloc[:, :-1]\n",
    "            y = df.iloc[:, -1]\n",
    "\n",
    "    # 2. Train Model\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # 3. Save Model\n",
    "    joblib.dump(model, MODEL_FILENAME)\n",
    "    print(f\"Model saved locally as {MODEL_FILENAME}\")\n",
    "\n",
    "    # 4. Upload to S3\n",
    "    s3 = boto3.client('s3')\n",
    "    try:\n",
    "        s3.upload_file(MODEL_FILENAME, BUCKET_NAME, MODEL_FILENAME)\n",
    "        print(f\"Successfully uploaded {MODEL_FILENAME} to s3://{BUCKET_NAME}/\")\n",
    "    except Exception as e:\n",
    "        print(f\"Upload failed: {e}\")\n",
    "        print(\"Ensure you have AWS credentials configured.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_upload_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a079c3b",
   "metadata": {},
   "source": [
    "### D. Lambda Function 1: The Predictor\n",
    "*   **Runtime**: Python 3.9\n",
    "*   **Trigger**: API Gateway (HTTP API)\n",
    "*   **Permissions**: `AmazonDynamoDBFullAccess`, `AmazonSNSFullAccess`, `AmazonS3ReadOnlyAccess`.\n",
    "*   **Layers**: We used `sklearn_light.zip` as a Lambda Layer to provide `scikit-learn` and `joblib` without exceeding the deployment size limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af36860",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'boto3'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mboto3\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'boto3'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "import joblib\n",
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "BUCKET_NAME = 'breast-cancer-prediction-models'\n",
    "MODEL_KEY = 'latest_model.pkl'\n",
    "DYNAMODB_TABLE = 'Patient_Entries'\n",
    "SNS_TOPIC_ARN = 'arn:aws:sns:eu-central-1:469541406278:MalignantAlerts'\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "dynamodb = boto3.resource('dynamodb')\n",
    "sns = boto3.client('sns')\n",
    "table = dynamodb.Table(DYNAMODB_TABLE)\n",
    "\n",
    "def load_model_from_s3():\n",
    "    print(\"Loading model from S3...\")\n",
    "    response = s3.get_object(Bucket=BUCKET_NAME, Key=MODEL_KEY)\n",
    "    model_stream = BytesIO(response['Body'].read())\n",
    "    model = joblib.load(model_stream)\n",
    "    print(\"Model loaded successfully.\")\n",
    "    return model\n",
    "\n",
    "# Load model globally to reuse across invocations\n",
    "model = load_model_from_s3()\n",
    "\n",
    "def process_doctor_feedback(body):\n",
    "    \"\"\"Handles the Tick/Cross feedback from the doctor.\"\"\"\n",
    "    case_id = body.get('id')\n",
    "    resolution = body.get('resolution')\n",
    "\n",
    "    if not case_id or not resolution:\n",
    "        return {'statusCode': 400, 'body': json.dumps('Missing id or resolution')}\n",
    "\n",
    "    print(f\"Processing feedback for Case {case_id}: {resolution}\")\n",
    "\n",
    "    # Update DynamoDB\n",
    "    try:\n",
    "        # 'status' is a reserved word, so we use ExpressionAttributeNames (#st)\n",
    "        table.update_item(\n",
    "            Key={'id': case_id},\n",
    "            UpdateExpression=\"SET doctor_resolution = :r, #st = :s\",\n",
    "            ExpressionAttributeNames={'#st': 'status'},\n",
    "            ExpressionAttributeValues={\n",
    "                ':r': resolution,\n",
    "                ':s': 'Resolved'\n",
    "            }\n",
    "        )\n",
    "        return {'statusCode': 200, 'body': json.dumps(f\"Case {case_id} resolved as {resolution}\")}\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating DynamoDB: {str(e)}\")\n",
    "        return {'statusCode': 500, 'body': json.dumps(f\"Database error: {str(e)}\")}\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    try:\n",
    "        print(\"Received event:\", json.dumps(event))\n",
    "        \n",
    "        # Parse body\n",
    "        if 'body' in event:\n",
    "            if isinstance(event['body'], str):\n",
    "                body = json.loads(event['body'])\n",
    "            else:\n",
    "                body = event['body']\n",
    "        else:\n",
    "            body = event\n",
    "\n",
    "        # CHECK OPERATION TYPE\n",
    "        if body.get('operation') == 'feedback':\n",
    "            return process_doctor_feedback(body)\n",
    "\n",
    "        # --- PREDICTION LOGIC ---\n",
    "        features = body.get('features')\n",
    "        case_id = body.get('id', 'unknown_id')\n",
    "\n",
    "        if not features:\n",
    "            return {\n",
    "                'statusCode': 400,\n",
    "                'body': json.dumps(\"Error: 'features' list is required.\")\n",
    "            }\n",
    "\n",
    "        prediction = model.predict([features])\n",
    "        result = 'M' if prediction[0] == 1 else 'B'\n",
    "\n",
    "        print(f\"Prediction for {case_id}: {result}\")\n",
    "\n",
    "        # Save to DynamoDB\n",
    "        item = {\n",
    "            'id': case_id,\n",
    "            'features': str(features),\n",
    "            'prediction': result,\n",
    "            'status': 'Pending Review'\n",
    "        }\n",
    "        table.put_item(Item=item)\n",
    "\n",
    "        # Send SNS Alert if Malignant\n",
    "        if result == 'M':\n",
    "            message = (\n",
    "                f\"URGENT: Malignant Case Detected\\n\\n\"\n",
    "                f\"Case ID: {case_id}\\n\"\n",
    "                f\"Prediction: Malignant (M)\\n\"\n",
    "                f\"Status: Pending Doctor Review\\n\\n\"\n",
    "                f\"Please log in to the dashboard to review this case immediately.\"\n",
    "            )\n",
    "            sns.publish(\n",
    "                TopicArn=SNS_TOPIC_ARN,\n",
    "                Message=message,\n",
    "                Subject=f\"Alert: Malignant Case {case_id}\"\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            'statusCode': 200,\n",
    "            'body': json.dumps({'prediction': result, 'id': case_id})\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps(f\"Internal Server Error: {str(e)}\")\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ff1345",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Phase 4: The Frontend (EC2 Web Server)\n",
    "\n",
    "We hosted the user interface on an EC2 instance (can be the same as the training one or a separate t2.micro).\n",
    "\n",
    "### A. Setup\n",
    "1.  **Install Web Server**: `sudo apt install apache2` (or nginx).\n",
    "2.  **Deploy Code**: Replaced `/var/www/html/index.html` with our custom HTML.\n",
    "3.  **Security Group**: Allowed Inbound HTTP (Port 80) traffic.\n",
    "\n",
    "### B. The Interface Code (`index.html`)\n",
    "This is the final, polished version of the UI that connects to the API Gateway.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c787bb9",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (760329767.py, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mbody { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; max-width: 1000px; margin: 0 auto; padding: 20px; background-color: #f8f9fa; color: #333; }\u001b[39m\n                                                                                       ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Breast Cancer Risk System</title>\n",
    "    <style>\n",
    "        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; max-width: 1000px; margin: 0 auto; padding: 20px; background-color: #f8f9fa; color: #333; }\n",
    "        .view { display: none; animation: fadeIn 0.5s; }\n",
    "        .active { display: block; }\n",
    "        @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }\n",
    "\n",
    "        /* Buttons */\n",
    "        .btn { padding: 12px 24px; margin: 5px; cursor: pointer; border-radius: 6px; font-size: 15px; border: none; transition: all 0.2s; font-weight: 600; }\n",
    "        .btn:disabled { opacity: 0.6; cursor: not-allowed; }\n",
    "        .btn-primary { background-color: #007bff; color: white; }\n",
    "        .btn-primary:hover { background-color: #0056b3; transform: translateY(-1px); }\n",
    "        .btn-success { background-color: #28a745; color: white; }\n",
    "        .btn-success:hover { background-color: #218838; }\n",
    "        .btn-danger { background-color: #dc3545; color: white; }\n",
    "        .btn-danger:hover { background-color: #c82333; }\n",
    "        .btn-outline { background: transparent; border: 1px solid #007bff; color: #007bff; }\n",
    "        .btn-outline:hover { background: #e7f1ff; }\n",
    "\n",
    "        /* File Upload */\n",
    "        .upload-area { border: 2px dashed #ccc; padding: 30px; text-align: center; background: white; border-radius: 10px; margin: 20px 0; transition: 0.3s; }\n",
    "        .upload-area:hover { border-color: #007bff; background: #f0f8ff; }\n",
    "\n",
    "        /* Table */\n",
    "        .table-container { max-height: 400px; overflow: auto; margin: 20px 0; border: 1px solid #dee2e6; border-radius: 5px; background: white; display: none; }\n",
    "        table { width: 100%; border-collapse: collapse; font-size: 13px; white-space: nowrap; }\n",
    "        th, td { padding: 10px; text-align: left; border-bottom: 1px solid #dee2e6; }\n",
    "        th { background-color: #e9ecef; position: sticky; top: 0; z-index: 10; font-weight: 600; }\n",
    "        tr:hover { background-color: #f8f9fa; }\n",
    "\n",
    "        /* Cards */\n",
    "        .case-card { background: white; border-left: 5px solid #dc3545; border-radius: 5px; padding: 15px; margin: 10px 0; display: flex; justify-content: space-between; align-items: center; box-shadow: 0 2px 8px rgba(0,0,0,0.05); }\n",
    "        .status-badge { padding: 4px 8px; border-radius: 4px; font-size: 12px; font-weight: bold; }\n",
    "        .status-malignant { background: #ffebee; color: #c62828; }\n",
    "\n",
    "        /* Logs */\n",
    "        #analysis-log { background: #2d2d2d; color: #00ff00; padding: 15px; border-radius: 5px; font-family: monospace; max-height: 200px; overflow-y: auto; margin-top: 20px; display: none; }\n",
    "    </style>\n",
    "    <script>\n",
    "        // --- CONFIGURATION ---\n",
    "        const PREDICT_URL = 'https://qu6y4f29lg.execute-api.eu-central-1.amazonaws.com/predict';\n",
    "\n",
    "        // --- CONSTANTS ---\n",
    "        const FEATURE_NAMES = [\n",
    "            \"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\", \"compactness_mean\", \"concavity_mean\", \"concave points_mean\", \"symmetry_mean\", \"fractal_dimension_mean\",\n",
    "            \"radius_se\", \"texture_se\", \"perimeter_se\", \"area_se\", \"smoothness_se\", \"compactness_se\", \"concavity_se\", \"concave points_se\", \"symmetry_se\", \"fractal_dimension_se\",\n",
    "            \"radius_worst\", \"texture_worst\", \"perimeter_worst\", \"area_worst\", \"smoothness_worst\", \"compactness_worst\", \"concavity_worst\", \"concave points_worst\", \"symmetry_worst\", \"fractal_dimension_worst\"\n",
    "        ];\n",
    "\n",
    "        // --- STATE ---\n",
    "        let loadedData = []; // Stores objects: { id: string, features: number[] }\n",
    "        let openCases = [];  // Stores Malignant cases waiting for review\n",
    "\n",
    "        // --- NAVIGATION ---\n",
    "        function showView(viewId) {\n",
    "            document.querySelectorAll('.view').forEach(el => el.classList.remove('active'));\n",
    "            document.getElementById(viewId).classList.add('active');\n",
    "            if(viewId === 'cases-view') renderOpenCases();\n",
    "        }\n",
    "\n",
    "        // --- FILE HANDLING ---\n",
    "        function handleFileUpload(event) {\n",
    "            const file = event.target.files[0];\n",
    "            if (!file) return;\n",
    "\n",
    "            const reader = new FileReader();\n",
    "            reader.onload = function(e) {\n",
    "                const text = e.target.result;\n",
    "                parseCSV(text, file.name);\n",
    "            };\n",
    "            reader.readAsText(file);\n",
    "        }\n",
    "\n",
    "        function parseCSV(csvText, fileName) {\n",
    "            try {\n",
    "                // 1. Extract Base ID from Filename\n",
    "                // Example: \"sample_patient_569.csv\" -> \"569\"\n",
    "                const nameNoExt = fileName.substring(0, fileName.lastIndexOf('.')) || fileName;\n",
    "                const parts = nameNoExt.split(/[_-\\s]+/);\n",
    "                const baseId = parts[parts.length - 1];\n",
    "\n",
    "                const lines = csvText.split('\\n').filter(line => line.trim() !== '');\n",
    "                loadedData = [];\n",
    "\n",
    "                // Determine start row (Skip header if present)\n",
    "                let startRow = 0;\n",
    "                if (/[a-zA-Z]/.test(lines[0])) {\n",
    "                    startRow = 1;\n",
    "                }\n",
    "\n",
    "                // Parse rows\n",
    "                const tempRows = [];\n",
    "                for (let i = startRow; i < Math.min(lines.length, 101); i++) {\n",
    "                    const rawValues = lines[i].split(',');\n",
    "\n",
    "                    // Filter for numeric values (to find features)\n",
    "                    const numericValues = rawValues\n",
    "                        .map(v => parseFloat(v))\n",
    "                        .filter(v => !isNaN(v));\n",
    "\n",
    "                    // We need at least 30 numeric features\n",
    "                    if (numericValues.length >= 30) {\n",
    "                        const features = numericValues.slice(-30);\n",
    "                        tempRows.push(features);\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                if (tempRows.length === 0) {\n",
    "                    alert(\"Could not parse any valid rows with 30 numeric features. Please check your CSV format.\");\n",
    "                    return;\n",
    "                }\n",
    "\n",
    "                // Assign IDs based on filename\n",
    "                loadedData = tempRows.map((features, index) => {\n",
    "                    // If single row, use the filename ID directly (e.g. \"569\")\n",
    "                    // If multiple rows, append index (e.g. \"569-1\", \"569-2\")\n",
    "                    let caseId = baseId;\n",
    "                    if (tempRows.length > 1) {\n",
    "                        caseId = `${baseId}-${index + 1}`;\n",
    "                    }\n",
    "                    return { id: caseId, features: features };\n",
    "                });\n",
    "\n",
    "                renderTable(loadedData);\n",
    "                document.getElementById('confirm-btn').disabled = false;\n",
    "\n",
    "            } catch (e) {\n",
    "                console.error(e);\n",
    "                alert(\"Error parsing CSV: \" + e.message);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        function renderTable(data) {\n",
    "            const container = document.getElementById('table-container');\n",
    "            const tableHead = document.getElementById('data-table-head');\n",
    "            const tableBody = document.getElementById('data-table-body');\n",
    "\n",
    "            // Clear previous\n",
    "            tableHead.innerHTML = '';\n",
    "            tableBody.innerHTML = '';\n",
    "\n",
    "            // Headers\n",
    "            const headerRow = document.createElement('tr');\n",
    "\n",
    "            // ID Column Header\n",
    "            const thId = document.createElement('th');\n",
    "            thId.innerText = \"Case ID\";\n",
    "            thId.style.minWidth = \"80px\";\n",
    "            headerRow.appendChild(thId);\n",
    "\n",
    "            // Feature Headers\n",
    "            FEATURE_NAMES.forEach(h => {\n",
    "                const th = document.createElement('th');\n",
    "                th.innerText = h;\n",
    "                headerRow.appendChild(th);\n",
    "            });\n",
    "            tableHead.appendChild(headerRow);\n",
    "\n",
    "            // Rows\n",
    "            data.forEach((item) => {\n",
    "                const tr = document.createElement('tr');\n",
    "\n",
    "                // ID Cell\n",
    "                const tdId = document.createElement('td');\n",
    "                tdId.innerText = item.id;\n",
    "                tdId.style.fontWeight = \"bold\";\n",
    "                tdId.style.backgroundColor = \"#f8f9fa\";\n",
    "                tr.appendChild(tdId);\n",
    "\n",
    "                // Feature Cells\n",
    "                item.features.forEach(val => {\n",
    "                    const td = document.createElement('td');\n",
    "                    td.innerText = val;\n",
    "                    tr.appendChild(td);\n",
    "                });\n",
    "                tableBody.appendChild(tr);\n",
    "            });\n",
    "\n",
    "            container.style.display = 'block';\n",
    "        }\n",
    "\n",
    "        function confirmData() {\n",
    "            if (loadedData.length > 0) {\n",
    "                document.getElementById('analyze-btn').disabled = false;\n",
    "                alert(`Data Confirmed! ${loadedData.length} patient records ready for analysis.`);\n",
    "            } else {\n",
    "                alert(\"No data to confirm. Please upload a valid CSV.\");\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // --- LOGIC: BATCH ANALYSIS ---\n",
    "        async function analyzeRisk() {\n",
    "            if (!loadedData || loadedData.length === 0) {\n",
    "                alert(\"No data loaded. Please upload a CSV first.\");\n",
    "                return;\n",
    "            }\n",
    "\n",
    "            showView('analyze-view');\n",
    "\n",
    "            // MIRROR TABLE TO ANALYZE VIEW\n",
    "            const originalTable = document.getElementById('table-container').innerHTML;\n",
    "            const targetContainer = document.getElementById('analysis-table-container');\n",
    "            targetContainer.innerHTML = originalTable;\n",
    "            targetContainer.style.display = 'block';\n",
    "\n",
    "            const logDiv = document.getElementById('analysis-log');\n",
    "            logDiv.style.display = 'block';\n",
    "            logDiv.innerHTML = \"Starting analysis...\\n\";\n",
    "\n",
    "            let processed = 0;\n",
    "\n",
    "            // Iterate through loaded data\n",
    "            for (let i = 0; i < loadedData.length; i++) {\n",
    "                const item = loadedData[i];\n",
    "                const features = item.features;\n",
    "                const patientId = item.id;\n",
    "\n",
    "                try {\n",
    "                    // Call API\n",
    "                    const response = await fetch(PREDICT_URL, {\n",
    "                        method: 'POST',\n",
    "                        headers: { 'Content-Type': 'application/json' },\n",
    "                        body: JSON.stringify({ features: features, id: patientId })\n",
    "                    });\n",
    "\n",
    "                    // ERROR HANDLING: Check if the request failed (e.g. 500 or 400)\n",
    "                    if (!response.ok) {\n",
    "                        const errorText = await response.text();\n",
    "                        throw new Error(`Server Error (${response.status}): ${errorText}`);\n",
    "                    }\n",
    "\n",
    "                    const result = await response.json();\n",
    "                    const prediction = result.prediction;\n",
    "\n",
    "                    // VALIDATION: Check if prediction is missing\n",
    "                    if (prediction === undefined) {\n",
    "                        throw new Error(\"Invalid response: 'prediction' field missing.\");\n",
    "                    }\n",
    "\n",
    "                    processed++;\n",
    "\n",
    "                    if (prediction === 'M') {\n",
    "                        // LOGIC: If Malignant -> Add to Open Cases\n",
    "                        openCases.push({\n",
    "                            id: patientId,\n",
    "                            features: features,\n",
    "                            date: new Date().toLocaleDateString(),\n",
    "                            status: 'Malignant'\n",
    "                        });\n",
    "                        logDiv.innerHTML += `[${patientId}] -> MALIGNANT (Added to Open Cases)\\n`;\n",
    "                    } else {\n",
    "                        // LOGIC: If Benign -> Auto-save to DB\n",
    "                        logDiv.innerHTML += `[${patientId}] -> Benign (Archived to DB)\\n`;\n",
    "                    }\n",
    "\n",
    "                } catch (error) {\n",
    "                    logDiv.innerHTML += `[${patientId}] Error: ${error.message}\\n`;\n",
    "                }\n",
    "\n",
    "                // Auto-scroll log\n",
    "                logDiv.scrollTop = logDiv.scrollHeight;\n",
    "            }\n",
    "\n",
    "            logDiv.innerHTML += `\\nAnalysis Complete. ${openCases.length} new cases require review.`;\n",
    "        }\n",
    "\n",
    "        // --- LOGIC: OPEN CASES ---\n",
    "        function renderOpenCases() {\n",
    "            const list = document.getElementById('cases-list');\n",
    "            list.innerHTML = '';\n",
    "\n",
    "            if (openCases.length === 0) {\n",
    "                list.innerHTML = \"<p style='text-align:center; color:#666;'>No open cases found.</p>\";\n",
    "                return;\n",
    "            }\n",
    "\n",
    "            openCases.forEach(c => {\n",
    "                const item = document.createElement('div');\n",
    "                item.className = 'case-card';\n",
    "                item.innerHTML = `\n",
    "                    <div>\n",
    "                        <strong>ID: ${c.id}</strong> <span style=\"color:#999; font-size:0.9em\">(${c.date})</span><br>\n",
    "                        <span class=\"status-badge status-malignant\">Potential Malignancy</span>\n",
    "                    </div>\n",
    "                    <div>\n",
    "                        <button class=\"btn btn-success\" onclick=\"resolveCase('${c.id}', 'Confirmed')\">‚úì Confirm</button>\n",
    "                        <button class=\"btn btn-danger\" onclick=\"resolveCase('${c.id}', 'False Positive')\">X False Positive</button>\n",
    "                    </div>\n",
    "                `;\n",
    "                list.appendChild(item);\n",
    "            });\n",
    "        }\n",
    "\n",
    "        function resolveCase(id, resolution) {\n",
    "            // Find the case data to send back to the backend\n",
    "            const caseData = openCases.find(c => c.id === id);\n",
    "            const features = caseData ? caseData.features : [];\n",
    "\n",
    "            if(confirm(`Mark case ${id} as ${resolution}?`)) {\n",
    "\n",
    "                // 1. Prepare the payload\n",
    "                // We add 'operation': 'feedback' so the Lambda knows this isn't a new prediction\n",
    "                const payload = {\n",
    "                    operation: 'feedback',\n",
    "                    id: id,\n",
    "                    resolution: resolution\n",
    "                };\n",
    "\n",
    "                // 2. Send to API\n",
    "                fetch(PREDICT_URL, {\n",
    "                    method: 'POST',\n",
    "                    headers: { 'Content-Type': 'application/json' },\n",
    "                    body: JSON.stringify(payload)\n",
    "                })\n",
    "                .then(response => {\n",
    "                    if (!response.ok) {\n",
    "                        throw new Error(`Server responded with ${response.status}`);\n",
    "                    }\n",
    "                    return response.json();\n",
    "                })\n",
    "                .then(data => {\n",
    "                    // 3. Success Handling\n",
    "                    alert(`‚úÖ Success! Feedback saved to DynamoDB.\\nCase ${id} marked as ${resolution}.`);\n",
    "                    // Remove from the list\n",
    "                    openCases = openCases.filter(c => c.id !== id);\n",
    "                    renderOpenCases();\n",
    "                })\n",
    "                .catch(error => {\n",
    "                    // 4. Error Handling (The \"Why it didn't work\" part)\n",
    "                    console.error(\"Feedback Error:\", error);\n",
    "                    alert(`‚ö†Ô∏è Action Failed: Could not save to DynamoDB.\\n\\nReason: ${error.message}\\n\\nWhy is this happening?\\n1. The Lambda function might not be updated yet to handle \"feedback\" requests.\\n2. The DynamoDB table might be missing or named incorrectly.\\n3. The API Gateway might be blocking the request (CORS).\\n\\nPlease check your Lambda logs for more details.`);\n",
    "                });\n",
    "            }\n",
    "        }\n",
    "    </script>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "    <!-- HOME VIEW -->\n",
    "    <div id=\"home-view\" class=\"view active\">\n",
    "        <h1 style=\"text-align:center;\">Breast Cancer Risk System</h1>\n",
    "\n",
    "        <!-- Upload Section -->\n",
    "        <div class=\"upload-area\">\n",
    "            <h3>üìÇ Upload Patient Data</h3>\n",
    "            <p>Drag and drop your CSV file here or click to browse</p>\n",
    "            <input type=\"file\" id=\"csvFileInput\" accept=\".csv\" onchange=\"handleFileUpload(event)\" />\n",
    "        </div>\n",
    "\n",
    "        <!-- Data Preview Table -->\n",
    "        <div id=\"table-container\" class=\"table-container\">\n",
    "            <table id=\"data-table\">\n",
    "                <thead id=\"data-table-head\"></thead>\n",
    "                <tbody id=\"data-table-body\"></tbody>\n",
    "            </table>\n",
    "        </div>\n",
    "\n",
    "        <!-- Actions -->\n",
    "        <div style=\"text-align:center; margin-top: 20px;\">\n",
    "            <button id=\"confirm-btn\" class=\"btn btn-success\" onclick=\"confirmData()\" disabled>‚úì Confirm Data</button>\n",
    "            <button id=\"analyze-btn\" class=\"btn btn-primary\" onclick=\"analyzeRisk()\" disabled>‚ö° Analyze Risk</button>\n",
    "            <button class=\"btn btn-outline\" onclick=\"showView('cases-view')\">üìÇ Open Cases</button>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <!-- ANALYZE VIEW (Log Output) -->\n",
    "    <div id=\"analyze-view\" class=\"view\">\n",
    "        <button onclick=\"showView('home-view')\" class=\"btn btn-outline\">‚Üê Back to Home</button>\n",
    "        <h2>Analysis in Progress</h2>\n",
    "\n",
    "        <!-- MIRRORED TABLE -->\n",
    "        <div id=\"analysis-table-container\" class=\"table-container\"></div>\n",
    "\n",
    "        <p>Processing uploaded records against the AI model...</p>\n",
    "\n",
    "        <div id=\"analysis-log\"></div>\n",
    "\n",
    "        <div style=\"margin-top: 20px; text-align: center;\">\n",
    "            <button class=\"btn btn-primary\" onclick=\"showView('cases-view')\">Go to Open Cases Review</button>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <!-- OPEN CASES VIEW -->\n",
    "    <div id=\"cases-view\" class=\"view\">\n",
    "        <button onclick=\"showView('home-view')\" class=\"btn btn-outline\">‚Üê Back to Home</button>\n",
    "        <h2>Open Cases</h2>\n",
    "        <p>The following cases were flagged as <strong>Malignant</strong> and require doctor confirmation.</p>\n",
    "        <div id=\"cases-list\"></div>\n",
    "    </div>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd26f9c",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Phase 5: Automation (Continuous Learning)\n",
    "\n",
    "This phase closes the loop. It ensures that confirmed cases are automatically fed back into the training dataset.\n",
    "\n",
    "### A. EventBridge Schedule\n",
    "*   **Type**: Schedule Rule\n",
    "*   **Cron Expression**: `cron(0 0 ? * SUN *)` (Every Sunday at Midnight)\n",
    "*   **Target**: Lambda Function 2 (Sync)\n",
    "\n",
    "### B. Lambda Function 2: The Sync Agent (`DynamoDB-S3-SyncLambda`)\n",
    "*   **Runtime**: Python 3.9\n",
    "*   **Permissions**: `AmazonS3FullAccess`, `AmazonDynamoDBFullAccess`.\n",
    "*   **Logic**:\n",
    "    1.  Scans DynamoDB for `Confirmed` or `False Positive` cases.\n",
    "    2.  Downloads the latest `patient_data_vX.csv`.\n",
    "    3.  Appends new rows (correcting diagnosis if False Positive).\n",
    "    4.  Uploads `patient_data_v(X+1).csv`.\n",
    "    5.  Marks DynamoDB items as `is_exported = True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea4fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import csv\n",
    "import io\n",
    "import os\n",
    "from boto3.dynamodb.conditions import Attr\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DYNAMODB_TABLE = 'Patient_Entries'\n",
    "S3_BUCKET = 'breast-cancer-cleaneddata'\n",
    "BASE_DATA_FILE = 'clean-data.csv'\n",
    "\n",
    "# HEADERS: ID first, then Diagnosis, then Features\n",
    "CSV_HEADERS = [\n",
    "    'id', 'diagnosis',\n",
    "    'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean',\n",
    "    'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "    'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "    'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se',\n",
    "    'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "    'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst'\n",
    "]\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "dynamodb = boto3.resource('dynamodb')\n",
    "table = dynamodb.Table(DYNAMODB_TABLE)\n",
    "\n",
    "def get_latest_dataset():\n",
    "    \"\"\"\n",
    "    Finds the latest version of the dataset.\n",
    "    Returns (content_string, next_version_number)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # List all files that look like patient_data_v*\n",
    "        response = s3.list_objects_v2(Bucket=S3_BUCKET, Prefix='patient_data_v')\n",
    "        \n",
    "        latest_version = 0\n",
    "        latest_file = BASE_DATA_FILE\n",
    "        \n",
    "        if 'Contents' in response:\n",
    "            for obj in response['Contents']:\n",
    "                key = obj['Key']\n",
    "                if key.startswith('patient_data_v') and key.endswith('.csv'):\n",
    "                    try:\n",
    "                        # Extract version number\n",
    "                        ver = int(key.replace('patient_data_v', '').replace('.csv', ''))\n",
    "                        if ver > latest_version:\n",
    "                            latest_version = ver\n",
    "                            latest_file = key\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "        \n",
    "        print(f\"Latest dataset found: {latest_file}\")\n",
    "        \n",
    "        # Download the content of the latest file\n",
    "        file_obj = s3.get_object(Bucket=S3_BUCKET, Key=latest_file)\n",
    "        content = file_obj['Body'].read().decode('utf-8')\n",
    "        \n",
    "        return content, latest_version + 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error finding latest dataset: {e}\")\n",
    "        # Fallback: try to get the base file\n",
    "        try:\n",
    "            print(f\"Falling back to base file: {BASE_DATA_FILE}\")\n",
    "            file_obj = s3.get_object(Bucket=S3_BUCKET, Key=BASE_DATA_FILE)\n",
    "            content = file_obj['Body'].read().decode('utf-8')\n",
    "            return content, 1\n",
    "        except Exception as inner_e:\n",
    "            print(f\"Critical Error: Could not find base file either. {inner_e}\")\n",
    "            # If absolutely nothing exists, start with headers\n",
    "            return \",\".join(CSV_HEADERS) + \"\\n\", 1\n",
    "\n",
    "def determine_diagnosis(prediction, resolution):\n",
    "    \"\"\"\n",
    "    Determines the true diagnosis (M/B) based on prediction and doctor feedback.\n",
    "    \"\"\"\n",
    "    pred_str = str(prediction).lower()\n",
    "    res_str = str(resolution).lower()\n",
    "    \n",
    "    # Check for 'm' (from your screenshot) or 'malignant'\n",
    "    is_predicted_malignant = ('m' == pred_str) or ('malignant' in pred_str)\n",
    "    \n",
    "    if 'confirmed' in res_str:\n",
    "        return 'M' if is_predicted_malignant else 'B'\n",
    "        \n",
    "    elif 'false positive' in res_str:\n",
    "        # Doctor disagrees.\n",
    "        # If predicted Malignant but marked False Positive -> It is Benign.\n",
    "        if is_predicted_malignant:\n",
    "            return 'B'\n",
    "        # If predicted Benign but marked False Positive (False Negative) -> It is Malignant.\n",
    "        else:\n",
    "            return 'M'\n",
    "            \n",
    "    return 'M' if is_predicted_malignant else 'B'\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    print(\"Starting Sync Process...\")\n",
    "    \n",
    "    # 1. Scan DynamoDB for new resolved cases\n",
    "    try:\n",
    "        response = table.scan(\n",
    "            FilterExpression=(\n",
    "                (Attr('doctor_resolution').eq('Confirmed') | Attr('doctor_resolution').eq('False Positive')) & \n",
    "                Attr('is_exported').ne('True')\n",
    "            )\n",
    "        )\n",
    "        items = response.get('Items', [])\n",
    "        \n",
    "        while 'LastEvaluatedKey' in response:\n",
    "            response = table.scan(\n",
    "                FilterExpression=(\n",
    "                    (Attr('doctor_resolution').eq('Confirmed') | Attr('doctor_resolution').eq('False Positive')) & \n",
    "                    Attr('is_exported').ne('True')\n",
    "                ),\n",
    "                ExclusiveStartKey=response['LastEvaluatedKey']\n",
    "            )\n",
    "            items.extend(response.get('Items', []))\n",
    "            \n",
    "        print(f\"Found {len(items)} new resolved cases to export.\")\n",
    "        \n",
    "        if not items:\n",
    "            return {\n",
    "                'statusCode': 200,\n",
    "                'body': json.dumps('No new resolved cases to export.')\n",
    "            }\n",
    "\n",
    "        # 2. Get Latest Dataset Content (Cumulative)\n",
    "        current_csv_content, next_version = get_latest_dataset()\n",
    "        \n",
    "        # 3. Append New Data\n",
    "        # We use StringIO to append to the existing string\n",
    "        csv_buffer = io.StringIO()\n",
    "        csv_buffer.write(current_csv_content)\n",
    "        \n",
    "        # Ensure we are on a new line if the previous file didn't end with one\n",
    "        if not current_csv_content.endswith('\\n'):\n",
    "            csv_buffer.write('\\n')\n",
    "            \n",
    "        writer = csv.DictWriter(csv_buffer, fieldnames=CSV_HEADERS)\n",
    "        # Do NOT write header, as it's already in the existing content\n",
    "        \n",
    "        items_to_update = []\n",
    "        \n",
    "        for item in items:\n",
    "            row = {}\n",
    "            \n",
    "            # 1. ID\n",
    "            row['id'] = item.get('id', 'unknown')\n",
    "            \n",
    "            # 2. Diagnosis\n",
    "            pred = item.get('prediction', '')\n",
    "            res = item.get('doctor_resolution', '')\n",
    "            row['diagnosis'] = determine_diagnosis(pred, res)\n",
    "            \n",
    "            # 3. Features (Unpacking the list from DynamoDB)\n",
    "            features_data = item.get('features', [])\n",
    "            \n",
    "            # Parse features if they are stored as a string (e.g. \"[1.0, 2.0]\")\n",
    "            features_list = []\n",
    "            if isinstance(features_data, str):\n",
    "                try:\n",
    "                    # Try JSON load first\n",
    "                    features_list = json.loads(features_data)\n",
    "                except:\n",
    "                    # Fallback: remove brackets and split\n",
    "                    try:\n",
    "                        clean_str = features_data.replace('[', '').replace(']', '')\n",
    "                        features_list = [float(x.strip()) for x in clean_str.split(',') if x.strip()]\n",
    "                    except:\n",
    "                        features_list = []\n",
    "            elif isinstance(features_data, list):\n",
    "                features_list = features_data\n",
    "            \n",
    "            # The CSV_HEADERS list has 'id' and 'diagnosis' at indices 0 and 1.\n",
    "            # The features start at index 2.\n",
    "            feature_names = CSV_HEADERS[2:]\n",
    "            \n",
    "            for i, feature_name in enumerate(feature_names):\n",
    "                if i < len(features_list):\n",
    "                    # Convert Decimal to float\n",
    "                    row[feature_name] = float(features_list[i])\n",
    "                else:\n",
    "                    # Fallback if list is shorter than expected\n",
    "                    row[feature_name] = 0.0\n",
    "            \n",
    "            writer.writerow(row)\n",
    "            items_to_update.append(item['id'])\n",
    "\n",
    "        # 4. Upload New Cumulative Version\n",
    "        new_filename = f'patient_data_v{next_version}.csv'\n",
    "        print(f\"Uploading cumulative data to {new_filename}...\")\n",
    "        \n",
    "        s3.put_object(\n",
    "            Bucket=S3_BUCKET,\n",
    "            Key=new_filename,\n",
    "            Body=csv_buffer.getvalue()\n",
    "        )\n",
    "        \n",
    "        # 5. Mark items as exported\n",
    "        print(f\"Marking {len(items_to_update)} items as exported...\")\n",
    "        for item_id in items_to_update:\n",
    "            table.update_item(\n",
    "                Key={'id': item_id},\n",
    "                UpdateExpression=\"set is_exported = :val\",\n",
    "                ExpressionAttributeValues={':val': 'True'}\n",
    "            )\n",
    "            \n",
    "        return {\n",
    "            'statusCode': 200,\n",
    "            'body': json.dumps(f\"Success! Appended {len(items)} cases to {new_filename}\")\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps(f\"Error syncing data: {str(e)}\")\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_first_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
